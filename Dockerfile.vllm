# DeepSeek-Coder-V2.5 + vLLM + RAG - RunPod Ready
FROM nvidia/cuda:12.1-devel-ubuntu22.04

# Variáveis de ambiente
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Configurações do modelo
ENV MODEL_NAME="deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct"
ENV VLLM_PORT=8000
ENV VLLM_HOST=0.0.0.0
ENV MAX_MODEL_LEN=32768
ENV GPU_MEMORY_UTIL=0.9

# Instalar dependências do sistema
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-dev \
    python3-pip \
    git \
    wget \
    curl \
    build-essential \
    software-properties-common \
    && rm -rf /var/lib/apt/lists/*

# Criar link simbólico para python
RUN ln -sf /usr/bin/python3.10 /usr/bin/python

# Atualizar pip
RUN python -m pip install --upgrade pip

# Instalar PyTorch com CUDA
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Copiar requirements
COPY requirements.txt /app/requirements.txt
WORKDIR /app

# Instalar dependências Python
RUN pip install -r requirements.txt

# Instalar vLLM (versão específica para compatibilidade)
RUN pip install vllm==0.2.7

# Instalar dependências adicionais para RAG
RUN pip install qdrant-client sentence-transformers

# Copiar código da aplicação
COPY . /app/

# Criar diretórios necessários
RUN mkdir -p /app/models /app/data /app/logs

# Dar permissões de execução
RUN chmod +x /app/server/vllm_server.py

# Script de inicialização
COPY docker/start.sh /app/start.sh
RUN chmod +x /app/start.sh

# Expor portas
EXPOSE 8000 6333 7860

# Healthcheck
HEALTHCHECK --interval=30s --timeout=30s --start-period=300s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Comando padrão - inicia servidor vLLM automaticamente
CMD ["/app/start.sh"]
