# üöÄ DeepSeek-Coder-V2.5 Local - Engenheiro de Software IA

IA de √∫ltima gera√ß√£o especializada em programa√ß√£o, engenharia reversa e desenvolvimento de software sem restri√ß√µes.
Baseado no **DeepSeek-Coder-V2.5** - o modelo mais avan√ßado para programa√ß√£o.

## ‚ö° Instala√ß√£o R√°pida

```bash
# 1. Clone o reposit√≥rio
git clone <seu-repo>
cd <seu-repo>

# 2. Instale depend√™ncias
pip install -r requirements.txt

# 3. Teste o funcionamento
python test_deepseek.py
```

## üéØ Uso B√°sico

```python
from models.deepseek_local import gerar_codigo, revisar_codigo, criar_projeto
from models.deepseek_local import EngenheiroDeSoftwareIA

# Usar modelo padr√£o (Lite - 16B)
codigo = gerar_codigo("Crie uma API REST em FastAPI")

# Ou escolher modelo espec√≠fico
ia_base = EngenheiroDeSoftwareIA(modelo="base")    # 236B - Mais poderoso
ia_lite = EngenheiroDeSoftwareIA(modelo="lite")    # 16B - Mais r√°pido
ia_legacy = EngenheiroDeSoftwareIA(modelo="legacy") # 6.7B - Compatibilidade

# Revisar c√≥digo existente
review = revisar_codigo(meu_codigo)

# Criar projeto completo
projeto = criar_projeto("Sistema de chat em tempo real", "Python")
```

## üîß RunPod.io Setup

1. **Criar Pod com GPU**:
   - Template: PyTorch 2.0+
   - GPU: RTX 4090 ou A100 (recomendado)
   - Storage: 50GB+

2. **Instalar no RunPod**:
```bash
git clone <seu-repo>
cd <seu-repo>
pip install -r requirements.txt
python test_deepseek.py
```

3. **Usar via Jupyter**:
```python
from models.deepseek_local import gerar_codigo
resultado = gerar_codigo("Seu prompt aqui")
print(resultado)
```

## üéõÔ∏è Configura√ß√µes

- **Modelo**: DeepSeek-Coder-V2.5-Lite (16B, quantizado 4-bit)
- **VRAM**: ~8-12GB necess√°rios (Lite) / ~40GB+ (Base)
- **Tokens**: At√© 32K tokens de contexto
- **Temperatura**: 0.7 (padr√£o, ajust√°vel)
- **Vers√µes**: Lite (16B), Base (236B), Legacy (6.7B)

## üî• Funcionalidades

- ‚úÖ **Gera√ß√£o de c√≥digo** em qualquer linguagem
- ‚úÖ **Revis√£o e otimiza√ß√£o** de c√≥digo existente  
- ‚úÖ **Cria√ß√£o de projetos** completos do zero
- ‚úÖ **Engenharia reversa** de sistemas
- ‚úÖ **Sem censura** - IA totalmente livre
- ‚úÖ **Otimizado para GPU** com quantiza√ß√£o

## üìä Performance

- **Velocidade**: ~20-50 tokens/segundo (RTX 4090)
- **Qualidade**: Especializado em programa√ß√£o
- **Mem√≥ria**: Otimizado para GPUs de 8GB+

## üö® Troubleshooting

**Erro de CUDA**:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Erro de mem√≥ria**:
- Reduza `max_tokens` para 1024 ou menos
- Use GPU com mais VRAM

**Modelo n√£o carrega**:
- Verifique conex√£o com internet
- Aguarde download inicial (~3-5GB)

## üéâ Pronto para Produ√ß√£o!

Este setup est√° otimizado para RunPod.io e pronto para uso profissional.
