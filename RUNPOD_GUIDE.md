# üî• ARSENAL DE GUERRA - RUNPOD POD GUIDE

## üöÄ **Deploy Autom√°tico no RunPod Pod**

### **üìã Pr√©-requisitos**
- Conta RunPod ativa
- GPU com pelo menos 24GB VRAM (recomendado: RTX 4090, A100)
- VSCode com extens√£o Continue instalada

---

## **üéØ PASSO 1: Criar Pod no RunPod**

### **1.1 Configura√ß√£o do Pod**
```
Template: PyTorch 2.1
GPU: RTX 4090 (24GB) ou A100 (40GB+)
Container Disk: 50GB m√≠nimo
Volume: 100GB (persistente)
Expose Ports: 8000
```

### **1.2 Configura√ß√µes Avan√ßadas**
```bash
# Environment Variables (opcional)
MODEL_ID=deepseek-ai/DeepSeek-Coder-V2-Instruct-70B
GPU_MEMORY_UTILIZATION=0.95
MAX_MODEL_LEN=32768
```

---

## **üéØ PASSO 2: Deploy Autom√°tico**

### **2.1 Conectar ao Pod**
```bash
# Via Web Terminal ou SSH
ssh root@SEU_POD_IP
```

### **2.2 Clone e Deploy**
```bash
# Ir para workspace persistente
cd /workspace

# Clonar projeto
git clone https://github.com/SEU_USUARIO/ai-dev.git
cd ai-dev

# Executar deploy autom√°tico
chmod +x docker/start.sh
./docker/start.sh
```

**üéâ PRONTO! O script faz tudo automaticamente:**
- ‚úÖ Detecta GPU e otimiza configura√ß√µes
- ‚úÖ Instala depend√™ncias necess√°rias
- ‚úÖ Baixa modelo DeepSeek automaticamente
- ‚úÖ Inicia servidor vLLM otimizado
- ‚úÖ Gera URLs de acesso
- ‚úÖ Testa funcionamento

---

## **üéØ PASSO 3: Configurar Continue VSCode**

### **3.1 Obter URL do Pod**
Ap√≥s o deploy, o script mostra:
```
üîó CONFIGURANDO URLS RUNPOD:
üì° Proxy URL: https://abc123def-8000.proxy.runpod.net
```

### **3.2 Configurar Continue**
1. Copie `vscode/continue_config.json` para `~/.continue/config.json`
2. Substitua `SEU_RUNPOD_ID` pela ID real do seu pod
3. Exemplo: `https://abc123def-8000.proxy.runpod.net/v1`

### **3.3 Testar Continue**
1. Abra VSCode
2. `Ctrl+Shift+P` ‚Üí "Continue: Open Chat"
3. Digite: "Ol√°, voc√™ est√° funcionando?"
4. Deve receber resposta do DeepSeek

---

## **üîß COMANDOS √öTEIS**

### **Verificar Status**
```bash
# Status do servidor
curl http://localhost:8000/health

# Listar modelos
curl http://localhost:8000/v1/models

# Ver processos
ps aux | grep vllm
```

### **Monitoramento**
```bash
# GPU usage
nvidia-smi
watch -n 1 nvidia-smi

# Logs
tail -f /var/log/syslog | grep vllm

# Espa√ßo em disco
df -h
du -sh /workspace/cache
```

### **Reiniciar Servidor**
```bash
# Parar servidor
pkill -f vllm

# Reiniciar
cd /workspace/ai-dev
./docker/start.sh
```

---

## **‚ö° OTIMIZA√á√ïES AUTOM√ÅTICAS**

### **Detec√ß√£o de GPU**
O script detecta automaticamente:
- **A100/H100**: Modelo FULL 70B, GPU util 95%
- **RTX 4090**: Modelo FULL 70B, GPU util 90%
- **RTX 3090**: Modelo LITE, GPU util 85%
- **Outras**: Configura√ß√£o conservadora

### **Cache Inteligente**
```bash
# Cache persistente em /workspace
HF_HOME=/workspace/cache/huggingface
TRANSFORMERS_CACHE=/workspace/cache/transformers

# Sobrevive a reinicializa√ß√µes do pod
```

### **Performance Tuning**
```bash
# Configura√ß√µes CUDA otimizadas
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Threading otimizado
OMP_NUM_THREADS=auto (baseado em CPU cores)

# vLLM otimizado para RunPod
--enable-prefix-caching
--max-num-batched-tokens 8192
```

---

## **üÜò SOLU√á√ÉO DE PROBLEMAS**

### **‚ùå "Out of Memory"**
```bash
# Reduzir utiliza√ß√£o GPU
export GPU_MEMORY_UTILIZATION=0.8

# Usar modelo menor
export MODEL_ID=deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

# Reiniciar
./docker/start.sh
```

### **‚ùå "Model Download Failed"**
```bash
# Verificar espa√ßo em disco
df -h

# Limpar cache se necess√°rio
rm -rf /workspace/cache/*

# Tentar novamente
./docker/start.sh
```

### **‚ùå "Continue n√£o conecta"**
```bash
# Verificar URL
cat /workspace/runpod_urls.txt

# Testar API
curl https://SEU_POD_ID-8000.proxy.runpod.net/health

# Verificar configura√ß√£o Continue
cat ~/.continue/config.json | grep apiBase
```

### **‚ùå "Pod muito lento"**
```bash
# Verificar se est√° usando GPU
nvidia-smi

# Verificar modelo carregado
curl http://localhost:8000/v1/models

# Verificar configura√ß√µes
ps aux | grep vllm
```

---

## **üí∞ OTIMIZA√á√ÉO DE CUSTOS**

### **Auto-shutdown**
```bash
# Desligar automaticamente em 2 horas
echo "sudo shutdown -h now" | at now + 2 hours

# Cancelar auto-shutdown
atq  # ver jobs
atrm JOB_ID  # cancelar
```

### **Uso Eficiente**
```bash
# Ligar pod apenas quando desenvolver
# Usar Continue VSCode normalmente
# Desligar pod quando terminar

# Custo t√≠pico:
# RTX 4090: ~$1.50/hora
# A100: ~$3.00/hora
```

---

## **‚úÖ CHECKLIST FINAL**

- [ ] Pod criado com GPU adequada
- [ ] Projeto clonado em `/workspace`
- [ ] Script `./docker/start.sh` executado
- [ ] Servidor respondendo em `/health`
- [ ] URL do proxy funcionando
- [ ] Continue VSCode configurado
- [ ] Teste de chat funcionando

---

## **üéØ PR√ìXIMOS PASSOS**

1. **Desenvolvimento**: Use Continue VSCode normalmente
2. **Monitoramento**: Acompanhe uso de GPU/mem√≥ria
3. **Backup**: C√≥digo fica em `/workspace` (persistente)
4. **Economia**: Desligue pod quando n√£o usar

**üî• Arsenal de Guerra pronto para a√ß√£o! üî•**
