#!/usr/bin/env bash
# ============================================================================
# ğŸ”¥ ARSENAL DE GUERRA - INSTALAÃ‡ÃƒO COM CORREÃ‡ÃƒO DE DEPENDÃŠNCIAS
# Script alternativo para resolver conflitos de dependÃªncias
# Autor: FULANOKS*CODER - Arsenal de Guerra Digital
# ============================================================================

set -euo pipefail

# Cores
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() { echo -e "${GREEN}[$(date +'%H:%M:%S')]${NC} $1"; }
error() { echo -e "${RED}[ERROR]${NC} $1" >&2; }
warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
info() { echo -e "${BLUE}[INFO]${NC} $1"; }

# Banner
echo -e "${RED}"
echo "============================================================================"
echo "ğŸ”¥ğŸ”¥ğŸ”¥ ARSENAL DE GUERRA - CORREÃ‡ÃƒO DE DEPENDÃŠNCIAS B200 ğŸ”¥ğŸ”¥ğŸ”¥"
echo "============================================================================"
echo "ğŸ¯ RESOLVENDO CONFLITOS DE DEPENDÃŠNCIAS"
echo "âš¡ INSTALAÃ‡ÃƒO ROBUSTA PARA B200 180GB"
echo "ğŸš€ AUTOR: FULANOKS*CODER - Arsenal de Guerra Digital"
echo "============================================================================"
echo -e "${NC}"

# Detectar ambiente
if [[ -n "${RUNPOD_POD_ID:-}" ]]; then
    export IS_RUNPOD=true
    export WORKSPACE_DIR="/workspace"
    export CACHE_DIR="/workspace/cache"
    log "âœ… RunPod detectado - ID: ${RUNPOD_POD_ID}"
else
    export IS_RUNPOD=false
    export WORKSPACE_DIR="$(pwd)"
    export CACHE_DIR="$HOME/.cache"
    warning "âš ï¸ Ambiente local detectado"
fi

# Detectar GPU
if command -v nvidia-smi &> /dev/null; then
    GPU_INFO=$(nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1)
    GPU_NAME=$(echo "$GPU_INFO" | cut -d',' -f1 | xargs)
    GPU_MEMORY=$(echo "$GPU_INFO" | cut -d',' -f2 | xargs)
    
    log "ğŸ® GPU detectada: $GPU_NAME ($GPU_MEMORY MB VRAM)"
    
    if [[ $GPU_MEMORY -ge 170000 ]]; then
        export GPU_TIER="B200_180GB"
        log "ğŸ”¥ğŸ”¥ğŸ”¥ B200 180GB DETECTADA - CONFIGURAÃ‡ÃƒO SUPREMA! ğŸ”¥ğŸ”¥ğŸ”¥"
    elif [[ $GPU_MEMORY -ge 75000 ]]; then
        export GPU_TIER="A100_80GB"
        log "ğŸš€ A100 80GB detectada"
    else
        export GPU_TIER="OTHER"
        warning "âš ï¸ GPU com VRAM limitada"
    fi
else
    error "âŒ NVIDIA GPU nÃ£o detectada!"
    exit 1
fi

# Configurar ambiente
log "ğŸ—ï¸ Configurando ambiente..."
mkdir -p "$CACHE_DIR"/{huggingface,transformers,datasets,pip}
mkdir -p "$WORKSPACE_DIR"/{logs,data,models}

# Configurar variÃ¡veis de ambiente
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:2048,expandable_segments:True"
export TOKENIZERS_PARALLELISM=false
export HF_HOME="$CACHE_DIR/huggingface"
export TRANSFORMERS_CACHE="$CACHE_DIR/transformers"
export HF_DATASETS_CACHE="$CACHE_DIR/datasets"
export PIP_CACHE_DIR="$CACHE_DIR/pip"
export HF_HUB_ENABLE_HF_TRANSFER=1

# Atualizar sistema
log "ğŸ”§ Atualizando sistema..."
python3 -m pip install --upgrade pip setuptools wheel

# Limpar cache pip se necessÃ¡rio
log "ğŸ§¹ Limpando cache pip..."
python3 -m pip cache purge

# InstalaÃ§Ã£o por etapas para evitar conflitos
log "ğŸ“¦ InstalaÃ§Ã£o por etapas para evitar conflitos..."

# Etapa 1: PyTorch (base)
info "ğŸ”¥ Etapa 1: Instalando PyTorch para CUDA 12.x..."
python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --force-reinstall

# Etapa 2: Transformers ecosystem
info "ğŸ¤– Etapa 2: Instalando Transformers ecosystem..."
python3 -m pip install transformers tokenizers accelerate huggingface-hub safetensors

# Etapa 3: vLLM (crÃ­tico)
info "âš¡ Etapa 3: Instalando vLLM..."
python3 -m pip install vllm

# Etapa 4: Web server
info "ğŸŒ Etapa 4: Instalando servidor web..."
python3 -m pip install fastapi "uvicorn[standard]" httpx sse-starlette python-multipart websockets

# Etapa 5: ML e utilities
info "ğŸ“Š Etapa 5: Instalando ML e utilities..."
python3 -m pip install numpy scipy pydantic python-dotenv requests rich tqdm psutil

# Etapa 6: Datasets e embeddings
info "ğŸ“š Etapa 6: Instalando datasets e embeddings..."
python3 -m pip install datasets sentence-transformers

# Etapa 7: OtimizaÃ§Ãµes opcionais
info "ğŸš€ Etapa 7: Tentando instalar otimizaÃ§Ãµes (opcional)..."
python3 -m pip install flash-attn --no-build-isolation || warning "âš ï¸ Flash Attention nÃ£o instalado (opcional)"
python3 -m pip install xformers || warning "âš ï¸ xFormers nÃ£o instalado (opcional)"
python3 -m pip install bitsandbytes || warning "âš ï¸ BitsAndBytes nÃ£o instalado (opcional)"

# Verificar instalaÃ§Ã£o
log "ğŸ” Verificando instalaÃ§Ã£o..."
python3 -c "
import torch
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA disponÃ­vel: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')
    print(f'âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f}GB')

try:
    import vllm
    print(f'âœ… vLLM: {vllm.__version__}')
except:
    print('âŒ vLLM nÃ£o instalado')

try:
    import transformers
    print(f'âœ… Transformers: {transformers.__version__}')
except:
    print('âŒ Transformers nÃ£o instalado')

try:
    import fastapi
    print(f'âœ… FastAPI: {fastapi.__version__}')
except:
    print('âŒ FastAPI nÃ£o instalado')
"

# Criar configuraÃ§Ã£o .env
log "âš™ï¸ Criando configuraÃ§Ã£o .env..."
cat > "$WORKSPACE_DIR/.env" << EOF
# Arsenal de Guerra - ConfiguraÃ§Ã£o B200 180GB
IS_RUNPOD=$IS_RUNPOD
WORKSPACE_DIR=$WORKSPACE_DIR
CACHE_DIR=$CACHE_DIR
GPU_TIER=$GPU_TIER

# Modelo
OPTIMAL_MODEL=deepseek-ai/DeepSeek-Coder-V2.5-Instruct
MODEL_NAME=deepseek-ai/DeepSeek-Coder-V2.5-Instruct

# vLLM B200 Supremo
TENSOR_PARALLEL_SIZE=1
GPU_MEMORY_UTILIZATION=0.98
MAX_MODEL_LEN=65536
MAX_NUM_BATCHED_TOKENS=32768
MAX_NUM_SEQS=1024
ENABLE_PREFIX_CACHING=true
USE_V2_BLOCK_MANAGER=true
SWAP_SPACE=0
CPU_OFFLOAD_GB=0

# Servidor
HOST=0.0.0.0
PORT=8000
API_PORT=8080

# Arsenal
UNCENSORED_MODE=true
DISABLE_CONTENT_FILTER=true
ALLOW_UNSAFE_CODE=true
ARSENAL_VERSION=2.5.0

# RunPod (substitua pela sua ID real)
RUNPOD_POD_ID=SEU_RUNPOD_ID
EOF

# Baixar modelo
log "ğŸ“¥ Baixando modelo DeepSeek..."
python3 -c "
from transformers import AutoTokenizer
from huggingface_hub import snapshot_download
import os

print('ğŸš€ Iniciando download do modelo...')
try:
    tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-Coder-V2.5-Instruct', cache_dir='$CACHE_DIR/huggingface')
    print('ğŸ“ Tokenizer baixado!')
    
    snapshot_download('deepseek-ai/DeepSeek-Coder-V2.5-Instruct', cache_dir='$CACHE_DIR/huggingface', ignore_patterns=['*.bin'])
    print('âœ… Modelo baixado!')
except Exception as e:
    print(f'âš ï¸ Erro no download: {e}')
"

# Criar script de start
log "ğŸ“ Criando script de inicializaÃ§Ã£o..."
cat > "$WORKSPACE_DIR/start_arsenal.sh" << 'EOF'
#!/bin/bash
source .env
echo "ğŸ”¥ğŸ”¥ğŸ”¥ ARSENAL B200 180GB - INICIANDO! ğŸ”¥ğŸ”¥ğŸ”¥"

# Verificar GPU
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader

# Iniciar vLLM
echo "ğŸš€ Iniciando vLLM B200 SUPREMO..."
python3 server/vllm_server.py &
VLLM_PID=$!

# Aguardar vLLM
echo "â³ Aguardando vLLM..."
for i in {1..120}; do
    if curl -s http://localhost:8000/health > /dev/null; then
        echo "âœ… vLLM B200 pronto!"
        break
    fi
    sleep 5
done

# Iniciar API
echo "ğŸŒ Iniciando API..."
python3 api/main.py &

echo "ğŸ¯ ARSENAL B200 180GB OPERACIONAL!"
echo "ğŸ“Š vLLM: http://localhost:8000"
echo "ğŸŒ API: http://localhost:8080"
echo "ğŸ’€ Execute no PC: python3 arsenal_auto.py"

wait
EOF

chmod +x "$WORKSPACE_DIR/start_arsenal.sh"

# Finalizar
echo -e "${GREEN}"
echo "============================================================================"
echo "ğŸ‰ğŸ‰ğŸ‰ ARSENAL B200 180GB INSTALADO COM CORREÃ‡ÃƒO! ğŸ‰ğŸ‰ğŸ‰"
echo "============================================================================"
echo -e "${WHITE}"
echo "ğŸš€ PRÃ“XIMOS PASSOS:"
echo "   1. ./start_arsenal.sh (iniciar servidores)"
echo "   2. NO PC: python3 arsenal_auto.py (configurar Continue)"
echo ""
echo "ğŸ¯ SERVIDORES:"
echo "   vLLM: http://localhost:8000"
echo "   API: http://localhost:8080"
echo ""
echo "ğŸ”¥ğŸ”¥ğŸ”¥ ARSENAL B200 180GB PRONTO PARA GUERRA DIGITAL! ğŸ”¥ğŸ”¥ğŸ”¥"
echo "ğŸ’€ FULANOKS*CODER - Arsenal de Guerra Digital"
echo -e "${NC}"
